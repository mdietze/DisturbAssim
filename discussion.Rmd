# Discussion

## Algorithm development and simulated data experiments

At a high-level, the simulated data experiments demonstrate that the Multinomial filter is able to address the fundamental problem that traditional data assimilation encounters when faced with disturbance events. Rather than nudging the posterior state stranded into a "no man's land" between the disturbed and undisturbed states, the Multinomial successfully makes a discrete jump in state. Through the simulated data experiments we also demonstrated: (1) That the algorithm is robust to false positives -- once in the disturbed state it does not interpret further dips in LAI as new disturbances since those data are consistent with the observation error around the model's predicted recovery trajectory; (2) That the algorithm is successfully able to fuse observations of multiple pools simultaneously; (3) That it can distinguish among multiple types of disturbance; (4) That it can accommodate disturbances that result in a discrete change in plant functional type (e.g., forest to grassland or agriculture); and (5) That the sharing of information across space in multi-site assimilations, which normally increases precision and handles missing observations, is not thrown off by disturbance events (e.g., reducing biomass in undisturbed sites). From a data assimilation perspective, the algorithm works as intended and is superior to conventional alternatives at detecting disturbance.

From a disturbance detection perspective, three things set the Multinomial assimilation apart from other conventional time-series based disturbance detection algorithms (as opposed to static image classifications), such as Landtrendr [@KENNEDY2010], CCDC (Continuous Change Detection and Classification) [@ZHU2014; @Pasquarella2017; @ZHU2020] and BFAST (Break detection For Additive Season and Trend) [@VERBESSELT2012]. First, most other algorithms flag disturbances as departures from the predicted value -- a rejection of the "status quo" hypothesis. With the multinomial, we are instead treating disturbance detection as a choice between competing hypotheses, assessing how much weight to place on the "status quo" versus different alternative disturbance options. Second, most of these algorithms rely on a moving-window approach as part of their "status quo" prediction, which requires accessing and processing a time-series of data from the past every time an prediction is updated. The iterative algorithms that form the basis for data assimilation (e.g., Kalman Filter) have on occasion been applied to disturbance detection (using statistical, rather than process-based model) and have demonstrated greater computational efficiency [@Ye2020]. @Ye2020 avoid the "no man's land" nudge problem by the simple expedient of performing threshold-based disturbance detection prior to assimilation and not assimilating disturbed sites. Third, other algorithms are relying on simple statistical models for their predictions of the status quo, such as harmonic time-series models, while the Multinomial model is relying on the predictions of a process-based ecosystem model. This has three distinct advantages: (1) We are leveraging greater process understanding in the status quo prediction, potentially making the algorithm more robust in the face of extreme events that are not disturbances (e.g., unusually cold or dry) but which alter the magnitude or phenology of seasonal cycles; (2) While not included in the simple "toy" model used in these analyses, process-based models also have the potential to leveraging greater process understanding in predicting the likelihood of disturbances, for example by accounting for fuel loads, fuel moisture, and ignition rates in predicting the likelihood of fire; (3) Because process-based models are predicting multiple pools and fluxes that can be compared to multiple distinct types of data, the Multinomial algorithm provides a natural way to fuse multiple types of data that would either reinforce a disturbance detection (if all sources are pointing in the same direction) or call it into question. While conventional disturbance detection algorithms are overwhelmingly based on multispectral remote sensing from either a single sensor or a pre-harmonized fusion of multiple sensors [e.g., Harmonized Landsat Sentinel-2, @CHEN2021; @SHANG2022], data assimilation approaches can simultanously integrate a wide range of relevant data types, for example lidar, microwave, thermal, solar-induced fluorescence, and field data. Data assimilation can also integrate a range of optical sensors (both multispectral and hyperspectral) based on their spectral response functions, rather than requiring pre-harmonization [@Shiklomanov2021; @Zhang2023]).
 

## Oregon case study

The most obvious issue with the initial application of the Multinomial filter to real-world data was the high incidence of filter divergence -- of the model becoming overconfident in itself and thus diverging from the observations. 
Filter divergence is not unique to this algorithm, but something that can occur in traditional filters as well. 
Indeed, there's no reason to belive that filter divergence is any more common in the Multinomial filter than in more traditional filters, such as EnKF, because in the absence of disturbance the Multinomial filter behaves exactly as EnKF would. 
The underlying causes of filter divergence are a result of either an underaccounting of model uncertainty or an overestimation of observation error in the data, both of which are likely at play in this example. 
On the model side, forecast uncertainty is associated with five factors: initial condition uncertainty, driver uncertainty, parameter uncertainty, parameter heterogenity, and process error [@Dietze2017b]. 
Since our goal here was a simple proof of concept, rather than a real world application, we did not formally account for uncertainty in model drivers (i.e., meteorology) or parameters. 
Alternative meteorological driver data products exist that account for uncertainties, such as the ERA5 ensemble reanalysis product [@Hersbach2020], and methods exist for propagating the uncertainties associated with downscaling such regional data products [@Rollinson2017].
Similarly, for actual carbon monitoring and forecasting we would recommend a more extensive multi-site Bayesian calibration so that parameter uncertainty can be propagated [@Fer2018; @Dietze2017a], preferably employing hierarchical approaches to also capture parameter heterogeneity (a.k.a. random effects), which can be substantial [@Fer2021].
Likewise, we would recommend a more robust estimation and propagation of process error as part of the data assimilation approach itself [@Raiho2020].
Ironically, the success of the existing model calibration at predicting AGB at our single calibration sites contributed to the underestimation of process error, since we failed to account for the uncertainties associated with extrapolating this single calibration to other sites across the landscape. 
Given the strong topographic and climatic gradients of the central Cascades, landscape heterogeneity in model performance is likely nontrivial.

In addition to underestimating model uncertainty, the AGB data product we are using, which relies on a single fixed residual error estimate, is likely overestimating the observation uncertainty. 
First, the assumption of constant variance is unlikely to be true because AGB is non-negative, which means the current interval estimates for low biomass sites include a substantial probability of negative biomass. 
More often the uncertainties in AGB are heteroskedastic and increasing in absolute magnitude as AGB increases, a property shared with the allometeric models used to estimate AGB in the field calibration data [@Dietze2008]. 
This heteroskedasticity particularly important for disturbance detection because it means we are likely significantly overestimating the observation error associated with low biomass (disturbed) conditions, contributing directly to the Multinomial model's inability to distinguish such biomass drops from observation error. 
Second, the AGB data product is does not distinguish random versus systematic errors [@Cameron2022], and in particular is not accounting for the spatial and temporal autocorrelation in observation errors. 
In reality, a site with higher than predicted AGB in one year is likely to have higher than predicted AGB the next year (positive temporal autocorrelation) and adjacent pixel are also likely to have higher than predicted AGB (positive spatial autocorrelation). 
These positive autocorrelations mean we are likely overestimating the uncertainty associated with change detection, since a substantial portion of this systematic observation error should cancel out [@Kennedy2023].
Overall, the failures of the default calibration, which ignored driver uncertainty, parameter uncertainty, and parameter heterogeneity while understimating process error and overestimating observation error, provide an illustrative case study in the care that must be taken when applying data assimilation approaches in general, and the Multinomial filter in particular, to real-world data

In contrast to our "off-the-shelf" application of the Multinomial filter, our computational experiments demonstrated that when we increase the model uncertainty and reduce the observation uncertainty that we significantly reduced the rate of filter divergence and were able to reliably detect all but the smallest disturbance events. 
Indeed, filter divergence declined, and disturbance detection increased, systematically as a function of the magnitude of the observation error. 
Somewhat surprisingly the computational experiments suggested that the Multinomial filter tended to be more sensitive to observation error than to model error, and suggesting that applications should prioritize making sure that observation errors are correctly accounted. 
Indeed, doing a better job at propagating model uncertainties correctly only becomes important once the observation errors are constrained.

## Future Directions: Current algorithm

In the following subsections we discuss ways that the proof-of-concept presented here could be applied and built upon. We start by addressing future directions that make use of the current algorithm "as is", discussing ways that we could better leverage multiple data constraints, improved disturbance priors, and existing disturbance data products.
In terms of multiple data constraints, it is worth noting that, unlike in the simulated data experiment, our real-world application only relied on a single data constraint.
If we had leveraged additional data constraints, we would have gained additional confidence in our ability to detect real disturbances.
One way to to do this is to bring in additional data on the same pool, in this case AGB, reducing the overall observation error. This could be done through some combination of field data [e.g., Forest Inventory and Analysis, CITE], lidar [e.g., GEDI, CITE], microwave vegetation optical depth [e.g., SMAP, CITE Koenings], or radar [e.g., BIOMASS, CITE]. 
This was not done in this example because data products based on different observations have a different spatial resolutions, which would need to be addressed. Fusing in a data assimilation framework is well established but was judged beyond the scope of the current study because it requires running a fully spatial assimilation rather than a simple site-scale timeseries model. Basically, one either needs to run the assimilation at a fine spatial resolution and use an observation operator to map many model grid cells to one observation, or one could run the assimilation at a coarse spatial resolution and use an observation operator to map one model grid cell to many observations [@Dietze2017a].

Another way would be to bring in additional data on different pools, such as LAI, which often has lower observation errors.
In addition to the direct increase in data volumes, the positive correlation between LAI and AGB would allow the assimilation algorithm to borrow strength indirectly (i.e. observations of LAI would help constrain AGB and observations of AGB would help constrain LAI). 
Existing LAI data products [e.g., MODIS, CITE] have the same spatial mismatch issue discussed above.
Alternatively, a data product based on LandSAT would be at the same resolution but would have required additional development [e.g., @Zhang2023] and would need to account for the observation error covariance between the two products (i.e. errors in data products based on the same underlying spectra would not be independent). 
In addition to bringing in additional data constratins on different pools, we could also constrain our disturbance estimates using observations on different ecosystem fluxes and processes, such as eddy covariance (carbon, water, and energy fluxes), solar induced fluorescence (a proxy for gross primary productivity), thermal imaging (a proxy for water stress and evapotranspiration).

In addition to constraining our estimates of disturbance through the ecosystem state variables, we can also improve them by improving our priors on the disturbance probability. 
In our simple case study we relied on static and spatially-homogenous prior probabilities on different disturbance rates, an approach somewhat similar to the simplest state-and-transition models of land use and disturbance [@Daniel2016].
More complex state-and-transition models are possible that allow these priors to be spatially heterogenous (e.g., relying on spatial covariates) or time evolving (e.g., relying on temporal covariates). Dynamic models are also possible that rely on the current state of a pixel (e.g., increasing fuel loads increase the probability of fire), the state of adjacent pixels (e.g., spatially contagious disturbances such as fire), or even those involving more distant spatial relations (e.g., dispersal kernels of biotic pests and pathogens) (CITATIONS).
In addition to relying on external state-and-transition models, one of the appeals of working with process-based ecosystem models is that many of they include submodules that represent different types of disturbance internally (e.g., fire, pests). In these cases we can either extract the model's internally predicted probabilities or simply rely on the frequency of events predicted across the ensemble of model runs.

The other way to improve upon the prior estimates of disturbance probability is to rely on external disturbance data that's not part of the assimilation itself. 
For example, in our Oregon case study it is clear that the Landtrendr disturbance product is "seeing" more about disturbance than is being expressed in the AGB product alone, as the the disturbance product is looking for different information (e.g., weighting bands differently, training to distinguish among types of disturbance not just a loss of biomass). 
Therefore, one alternative to relying on models to predict disturbance priors is to use the disturbance product and its classification error statistics to specify priors itself to identify the error.
This approach could be particularly valuable for distinguishing among alternative disturbance types (e.g., forest wildfire, forestry, and conversion to agriculture or development), especially for disturbance products that make use of bands outside of the normal optical range (e.g., thermal-based active fire products).
Applying this approach was not done in our test case because we wanted to keep the disturbance product separate for purposes of validation, but would be relatively straightforward to implement.
It's important to note that when using external disturbance data as priors we're still not prescribing disturbances deterministically, during the assimilation observations about ecosystem pools and fluxes would thus either reinforce these products or call them into question. 
Finally, it is worth nothing that relying on processed-based models and external disturbance data products are not mutually exclusive.
The fusion of disturbance products and disturbance models could be part of the future development of the Multinomial filter itself (see next subsection), but may be simpler to handle as part of the prior construction. For example, one could start with the models as priors and then update these using one or more disturbance product observations [e.g., using the Bayesian Updating of Land Cover (BULC) algorithm, @CARDILLE2016; @Crowley2019] and then use these posteriors as the priors in the data assimilation.


## Future Directions: Computational challenges

* Analytical approximation of sequential beta-binomial then KF vs full joint model

* Scaling up -> emulation
    * Applied at scale full model would be both computationally prohibitive and highly redundant (similar sites, such as spatially adjacent, are going to have very similar inputs and output)
    * run full Bayesian model for a subset of locations stratified by relevant variables (IC, observed data, possibly also met, soils, etc.)
    * build ML emulator to predict outcome of full Bayesian model
    * use ML emulator to predict full model; interpolate in env/obs space -> map to physical space


## Future Directions: Algorithm Development

  * Multisite needs a way of estimating $\rho$ by site with cross site correlations, rather than unique $\rho$ for all permutations
    * for $\rho$ handle the covariances of nearby sites -- disturbance in one usually increases the probability of disturbance in others
    * similarly, need to be able to compose Multisite $\mu_f$ and $P_f$, from individual site values with reasonable approximations of cross-[site x pool] correlations

* would be good to add 'memory' to algorithm so further evidence of disturbance reinforces initial detection (similar to BLC); would allow reduction in time step and greater sensor fusion
  * example case: initially overlapping but diverge
  * Would like to add look-back capabilities (ensemble backward smoothing) to update assignments based on more recent info

* PFT switching
      * mention parallel PFT ensembles
      * need to protect against long-term PFT leakage; related to more general need to "look back"



* Scaling up -> spatially implicit
  * work at larger spatial scales and account for subgrid disturbance heterogeneity implicitly 
    * ED2
    * Contagion [@McCabe2019]




## Conclusion

* Implications  (borrow text from CMS proposals)
  * Improving MRV
  * Recovery forecasting
  * Disturbance nowcasting
    * requires reducing temporal resolution










