# Discussion

## Algorithm development and simulated data experiments

Taken as a whole, the simulated data experiments demonstrate that the Multinomial filter is able to address the fundamental problem that traditional data assimilation encounters when faced with disturbance events. Rather than nudging the posterior state stranded into a "no man's land" between the disturbed and undisturbed states, the Multinomial successfully makes a discrete jump in state. Through the simulated data experiments we also demonstrated: (1) That the algorithm is robust to false positives -- once in the disturbed state it does not interpret further dips in biomass as new disturbances since those data are consistent with the observation error around the model's predicted recovery trajectory; (2) That the algorithm is successfully able to fuse observations of multiple pools simultaneously; (3) That it can distinguish among multiple types of disturbance; (4) That it can accommodate disturbances that result in a discrete change in plant functional type (e.g., forest to grassland or agriculture); and (5) That the sharing of information across space in multi-site assimilations, which normally increases precision and handles missing observations, is not thrown off by disturbance events (e.g., reducing biomass in undisturbed sites). From a data assimilation perspective, the algorithm works as intended and is superior to conventional data assimilation algorithms at detecting disturbance.

From a disturbance detection perspective, three things set the Multinomial assimilation apart from other conventional time-series based disturbance detection algorithms (as opposed to static image classifications), such as Landtrendr [@KENNEDY2010], CCDC (Continuous Change Detection and Classification) [@ZHU2014; @Pasquarella2017; @ZHU2020] and BFAST (Break detection For Additive Season and Trend) [@VERBESSELT2012]. First, most other algorithms flag disturbances as departures from the predicted value -- a rejection of the undisturbed "status quo" hypothesis. With the Multinomial, we are instead treating disturbance detection as a choice between competing hypotheses, assessing how much weight to place on the undisturbed "status quo" versus different alternative disturbance options. Second, most of these algorithms rely on a moving-window approach as part of their "status quo" prediction, which requires accessing and processing a time-series of data from the past every time a prediction is updated. By contrast, the iterative algorithms that form the basis for data assimilation (e.g., Kalman Filter) only need to look at one observation at a time. Such algorithms have on occasion been applied to disturbance detection (using statistical, rather than process-based model) and have demonstrated greater computational efficiency [@Ye2020]. @Ye2020 avoids the "no man's land" nudge problem by the simple expedient of performing threshold-based disturbance detection prior to assimilation and not assimilating disturbed sites. Third, other algorithms rely on simple statistical models for their predictions of the status quo, such as harmonic time-series models, while the Multinomial model can make use of predictions from process-based ecosystem models. This has three distinct advantages: (1) We are leveraging greater process understanding in the status quo prediction, potentially making the Multinomial model more robust in the face of extreme events that are not disturbances (e.g., unusually cold or dry) but which alter the magnitude or phenology of seasonal cycles; (2) While not included in the simple "toy" model used in these analyses, process-based models also have the potential to leverage greater process understanding in predicting the likelihood of disturbances, for example by accounting for fuel loads, fuel moisture, and ignition rates in predicting the likelihood of fire; (3) Because process-based models are predicting multiple pools and fluxes that can be compared to multiple distinct types of data, the Multinomial algorithm provides a natural way to fuse multiple types of data that would either reinforce a disturbance detection (if all sources are pointing in the same direction) or call it into question. While conventional disturbance detection algorithms are overwhelmingly based on multispectral remote sensing from either a single sensor or a pre-harmonized fusion of multiple sensors [e.g., Harmonized Landsat Sentinel-2, @CHEN2021; @SHANG2022], data assimilation approaches can simultaneously integrate a wide range of relevant data types, for example lidar, microwave, thermal, solar-induced fluorescence, and field data. Data assimilation can also integrate a range of optical sensors (both multispectral and hyperspectral) based on their spectral response functions, rather than requiring pre-harmonization [@Shiklomanov2021; @Zhang2023]).
 

## Oregon case study

The most obvious issue with the initial application of the Multinomial filter to real-world data was the high incidence of filter divergence -- of the model becoming overconfident in itself and thus diverging from the observations. 
Filter divergence is not unique to this algorithm, but something that can occur in traditional filters as well [@kalnay2003; @lewis2006]. 
Indeed, there's no reason to believe that filter divergence is any more common in the Multinomial filter than in more traditional filters, such as EnKF, because in the absence of disturbance the Multinomial filter behaves exactly as EnKF would. 
The underlying causes of filter divergence are a result of either an underaccounting of model uncertainty or an overestimation of observation error in the data, both of which are likely at play in this example. 

On the model side, forecast uncertainty is associated with five factors: initial condition uncertainty, driver uncertainty, parameter uncertainty, parameter heterogeneity, and process error [@Dietze2017b]. 
Since our goal here was a simple proof of concept, rather than a real world application, we did not formally account for uncertainty in model drivers (i.e., meteorology) or parameters.
Alternative meteorological driver data products exist that account for uncertainties, such as the ERA5 ensemble reanalysis product [@Hersbach2020], and methods exist for propagating the uncertainties associated with downscaling such regional data products [@Rollinson2017].
Similarly, for actual carbon monitoring and forecasting we would recommend a more extensive multi-site Bayesian calibration so that parameter uncertainty can be propagated [@Fer2018; @Dietze2017a], preferably employing hierarchical approaches to also capture parameter heterogeneity (a.k.a. random effects), which can be substantial [@Fer2021].
Likewise, we would recommend a more robust estimation and propagation of process error as part of the data assimilation approach itself [@Raiho2020].
Ironically, the success of the existing model calibration at predicting AGB at our single calibration sites contributed to the underestimation of process error, since we failed to account for the uncertainties associated with extrapolating this single calibration to other sites across the landscape. 
Given the strong topographic and climatic gradients of the central Cascades, landscape heterogeneity in model performance is likely nontrivial.

In addition to underestimating model uncertainty, the AGB data product we are using, which relies on a single fixed residual error estimate, is likely overestimating the observation uncertainty. 
First, the assumption of constant variance is unlikely to be true because AGB is non-negative, which means the current interval estimates for low biomass sites include a substantial probability of negative biomass. 
More often the uncertainties in AGB are heteroskedastic and increasing in absolute magnitude as AGB increases, a property shared with the allometric models used to estimate AGB in field calibration data [@van2005; @berner2016]. 
This heteroskedasticity is particularly important for disturbance detection because it means we are likely significantly overestimating the observation error associated with low biomass (disturbed) conditions, contributing directly to the Multinomial model's inability to distinguish such biomass drops from observation error. 
Second, the Landtrendr AGB data product does not distinguish random versus systematic errors [@Cameron2022], and in particular is not accounting for the spatial and temporal autocorrelation in observation errors. 
In reality, a site with higher than predicted AGB in one year is likely to have higher than predicted AGB the next year (positive temporal autocorrelation) and adjacent pixel are also likely to have higher than predicted AGB (positive spatial autocorrelation). 
These positive autocorrelations mean we are likely overestimating the uncertainty associated with change detection, since a substantial portion of this systematic observation error should cancel out [@Kennedy2023].
Overall, the failures of the default calibration, which ignored driver uncertainty, parameter uncertainty, and parameter heterogeneity while underestimating process error and overestimating observation error, provide an illustrative case study in the care that must be taken when applying data assimilation approaches in general, and the Multinomial filter in particular, to real-world data

In contrast to our "off-the-shelf" application of the Multinomial filter, our computational experiments demonstrated that when we increase the model uncertainty and reduce the observation uncertainty, we significantly reduced the rate of filter divergence and were able to reliably detect all but the smallest disturbance events. 
Indeed, filter divergence declined, and disturbance detection increased, systematically as a function of the magnitude of the observation error. 
Somewhat surprisingly the computational experiments suggested that the Multinomial filter tended to be more sensitive to observation error than to model error, which implies that applications should prioritize making sure that observation errors are well constrained. 
Indeed, doing a better job at propagating model uncertainties correctly only becomes important once the observation errors are constrained.

## Future Directions: Algorithm Development

In the following subsections we discuss ways that the proof-of-concept presented here could be applied and built upon. We start by addressing future directions that make use of the current algorithm "as is", discussing ways that we could better leverage multiple data constraints, improved disturbance priors, and existing disturbance data products. We then discuss three possible longer-term improvements: accounting for space when estimating the probability of disturbance, $\vec{\rho_t}$; adding memory to the algorithm to be able to better detect disturbance occurrence and type; and using spatially-implicit approaches that track fractional area.

In terms of multiple data constraints, it is worth noting that, unlike in the simulated data experiment, our real-world application only relied on a single data constraint.
If we had leveraged additional data constraints, we would have gained additional confidence in our ability to detect real disturbances.
One way to do this is to bring in additional data on the same pool, in this case AGB, reducing the overall observation error. This could be done through some combination of field data [e.g., Forest Inventory and Analysis, @burrill_2021], lidar [e.g., GEDI, @duncanson2022], microwave vegetation optical depth [e.g., SMAP, @konings2017], or radar [@sinha2015review]. 
This was not done in this example because data products based on different observations have different spatial resolutions. Data assimilation approaches for fusing data with different resolutions are well established but were judged beyond the scope of the current study because they requires running a fully-spatial assimilation, rather than a simple site-scale time series model. Basically, one either needs to run the assimilation at a fine spatial resolution and use an observation operator to map many model grid cells to one observation, or to run the assimilation at a coarse spatial resolution and use an observation operator to map one model grid cell to many observations [@Dietze2017a].

Another way to leverage additional data constraints would be to bring in observation of different pools, such as LAI, which often has lower observation errors.
In addition to the direct increase in data volumes, the positive correlation between model predicted LAI and AGB would allow the assimilation algorithm to borrow strength indirectly (i.e. observations of LAI would help constrain AGB and observations of AGB would help constrain LAI). 
Existing LAI data products [e.g., MODIS, @yan2016] have the same spatial mismatch issue discussed above.
Alternatively, a data product based on Landsat would be at the same resolution but would have required additional development [e.g., @Zhang2023] and would need to account for the observation error covariance between the two products (i.e. errors in data products based on the same underlying spectra would not be independent). 
In addition to bringing in additional data constraints on different pools, we could also constrain our disturbance estimates using observations on different ecosystem fluxes and processes, such as eddy covariance (carbon, water, and energy fluxes), solar induced fluorescence (a proxy for gross primary productivity), and thermal imaging (a proxy for water stress and evapotranspiration).

In addition to constraining our estimates of disturbance through the ecosystem state variables, we could also improve our disturbance probability priors. 
In our simple case study we relied on static and spatially-homogeneous prior probabilities on different disturbance rates, an approach analogous to the simplest state-and-transition models of land use and disturbance [@Daniel2016].
It is possible to use more complex state-and-transition models that would allow priors to be spatially heterogeneous (e.g., relying on spatial covariates) or time evolving (e.g., relying on temporal covariates). Similarly, it is also possible to build state-and-transition models that leverage the current state of a pixel (e.g., increasing fuel loads increase the probability of fire), the state of adjacent pixels (e.g., spatially contagious disturbances such as fire), or even those involving more distant spatial relations (e.g., dispersal kernels of biotic pests and pathogens) [@johnstone2011; @hudgins2017].
In addition to relying on external state-and-transition models, one of the appeals of working with process-based ecosystem models is that many of them include submodules that represent different types of disturbance internally (e.g., fire, pests). In these cases we can either extract the model's internally predicted probabilities or simply rely on the frequency of events predicted across the ensemble of model runs.

The other way to improve upon the prior estimates of disturbance probability is to rely on external disturbance data that's not part of the assimilation itself. 
For example, in our Oregon case study it is clear that the Landtrendr disturbance product is "seeing" more about disturbance than is being expressed in the AGB product alone, as the disturbance product is looking for different information (e.g., weighting bands differently, training to distinguish among types of disturbance not just a loss of biomass). 
Therefore, one alternative to relying on models to predict disturbance priors is to use the disturbance product, and its classification error statistics, to specify priors.
This approach could be particularly valuable for distinguishing among alternative disturbance types (e.g., forest wildfire, forestry, and conversion to agriculture or development), especially for disturbance products that make use of bands outside of the normal optical range (e.g., thermal-based active fire products).
Applying this approach was not done in our test case because we wanted to keep the disturbance product separate for purposes of validation, but would be relatively straightforward to implement.
It's important to note that when using external disturbance data as priors we're still not prescribing disturbances deterministically. During the assimilation, additional observations about ecosystem pools and fluxes would thus either reinforce these products or call them into question. 
Finally, it is worth noting that relying on process-based models and external disturbance data products are not mutually exclusive.
The fusion of disturbance products and disturbance models could be part of the future development of the Multinomial filter itself (see next subsection), but may be simpler to handle as part of the prior construction. For example, one could start with the models as priors and then update these using one or more disturbance product observations [e.g., using the Bayesian Updating of Land Cover (BULC) algorithm, @CARDILLE2016; @Crowley2019] and then use these posteriors as the priors in the data assimilation.

In terms of spatial disturbance probability, the current filter estimates a whole vector of probabilities, one for each site, but does not explicitly account for spatial adjacency. In practice, almost all types of disturbance involve some degree of shared risk, if not true spatial contagion, whereby a disturbance at one site usually increases the probability of disturbance in near-by sites. Accounting for this could be done by adding a hierarchical layer to the estimation of $\rho$ that includes a spatial covariance structure, for example by using a link function (e.g., logit) and modeling the covariance as a multivariate Normal with a standard distance-dependent covariance model [@Banerjee2014] or spatial basis functions and random effects [@Wikle2019].

As for the idea of incorporating memory, one limitation of the existing approach is that, like most data assimilation filters, it is strictly Markovian - states are updated solely based on the current model state and current observations. Imagine the case where an anomalously low AGB value is observed but at the next time point AGB returns to normal. At the time that the low observation is made it may trigger the Multinomial filter to predict a high probability of disturbance, but after the next observation becomes available it becomes much more likely that the low value was simply observation error. In this case what we want is the ability not just to restore the AGB to the undisturbed state, but also to jump back to the previous observation and assign it to be undisturbed as well. Similarly, if a disturbance occurs but observations are compatible with two types of disturbance (e.g., clear cut versus conversion to agriculture), the algorithm may assign both a 50/50 probability at that time point. At the next time point it may update that assignment based on new information (e.g., the new vegetation is a crop), in which case we also want to jump back in time and say that the original disturbance was agricultural conversion. Implementing this "memory" feature is more challenging, as it requires writing a statistical model that accounts for multiple points in time and more complex multi-temporal disturbance state scenarios, as well as the informatics pipelines to save previous states and restart model ensembles from an earlier point in time. 

A final potential algorithm improvement would be to adopt a spatially implicit approach to tracking disturbance. Spatially implicit approaches are a common feature of global vegetation models, which for computational reasons might represent a larger (e.g., 0.5-by-0.5 degree) grid cell as containing multiple vegetation types, each with a fractional area, rather than keeping track of where in each grid cell those vegetation types are located. A subset of these models also keep track of both disturbance events and time since disturbance (a.k.a. patch age) in this way, updating fractional areas dynamically [@Moorcroft2001]. More recently, @McCabe2019 proposed a way to account not just for fractional area but also patch adjacency using a spatially implicit approach, allowing for the model to better account for spatial contagion and the distribution of patch sizes. Conceptually, the disturbance data assimilation approach we've presented here should be able to keep track of fractional areas of disturbance instead of a discrete disturbed/undisturbed state, for example by adopting a Dirichlet data model instead of a Multinomial.

## Future Directions: Computational challenges

One of the challenges in scaling up the Multinomial filter is the computational cost involved. Unlike a traditional EnKF, the Analysis step of the data assimilation does not have a full analytically solution, and instead needs to be evaluated numerically, for example through standard Bayesian MCMC approaches as was done in this paper. 
Because MCMC is too computationally costly to apply using brute force on anything larger than an individual landscape, scaling up will require approximations to the full algorithm. 
Analytically, instead of solving the full Multinomial filter jointly, it may be possible to approximate the full model by decomposing the filter sequentially, first applying EnKF to each alternative disturbance state, analytically generating independent posteriors for each $X^L_t$, and then applying a Dirichlet-Multinomial model to update $\vec{\rho_t}$, treating $X^L_t$ as known rather than jointly estimated. This approach has yet to be fully fleshed out and it remains to be seen how well this approximation works in practice.

An alternative to analytical approximation is to rely on machine learning approaches to build an emulator (a.k.a. surrogate model) [@Fer2018]. While emulators are often used to approximate process-based models, predicting what the model would have output given a set of inputs, here we want to run the Multinomial filter for a subset of locations, stratified by relevant variables (initial conditions, observed data constraints, and possibly also covariates like climate, soils, etc.), and then construct an emulator to the Analysis step, predicting what the Multinomial filter would output (probability of disturbance, ecosystem pool means and variances) as a function of the Forecast model state and the observed data constraints. The emulator is then applied to places where the full model was not run, in essence interpolating in environmental space and mapping this back to physical space.

## Conclusion

Over the course of this paper we discussed the potential advantages of model-data assimilation for improving MRV of the terrestrial carbon cycle, the importance of disturbance to carbon MRV, and the limitations of current data assimilation algorithms to account for disturbance. We then derived a new data assimilation algorithm, the Multinomial filter, based on the idea of accounting for the discrete nature of disturbance, and demonstrated the ability of this algorithm to capture a range of simulated and real-world disturbances. We then discussed ways that this algorithm could be further improved. Overall, the Multinomial filter has the potential to improve not only MRV but also the near real-time disturbance detection, with important implications at scales from national (UN reporting) down to local (natural climate solutions). By allowing a more realistic representation of disturbance in process-based models, the algorithm also opens the door to the incorporation of ecosystem recovery forecasts, making possible more informed and efficient management of post-disturbance recovery.
