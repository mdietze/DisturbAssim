# Discussion

## Algorithm development and simulated data experiments

At a high-level, the simulated data experiments demonstrate that the Multinomial filter is able to address the fundamental problem that traditional data assimilation encounters when faced with disturbance events. Rather than nudging the posterior state stranded into a "no man's land" between the disturbed and undisturbed states, the Multinomial successfully makes a discrete jump in state. Through the simulated data experiments we also demonstrated: (1) That the algorithm is robust to false positives -- once in the disturbed state it does not interpret further dips in LAI as new disturbances since those data are consistent with the observation error around the model's predicted recovery trajectory; (2) That the algorithm is successfully able to fuse observations of multiple pools simultaneously; (3) That it can distinguish among multiple types of disturbance; (4) That it can accommodate disturbances that result in a discrete change in plant functional type (e.g., forest to grassland or agriculture); and (5) That the sharing of information across space in multi-site assimilations, which normally increases precision and handles missing observations, is not thrown off by disturbance events (e.g., reducing biomass in undisturbed sites). From a data assimilation perspective, the algorithm works as intended and is superior to conventional alternatives at detecting disturbance.

From a disturbance detection perspective, three things set the Multinomial assimilation apart from other conventional time-series based disturbance detection algorithms (as opposed to static image classifications), such as Landtrendr [@KENNEDY2010], CCDC (Continuous Change Detection and Classification) [@ZHU2014; @Pasquarella2017; @ZHU2020] and BFAST (Break detection For Additive Season and Trend) [@VERBESSELT2012]. First, most other algorithms flag disturbances as departures from the predicted value -- a rejection of the "status quo" hypothesis. With the multinomial, we are instead treating disturbance detection as a choice between competing hypotheses, assessing how much weight to place on the "status quo" versus different alternative disturbance options. Second, most of these algorithms rely on a moving-window approach as part of their "status quo" prediction, which requires accessing and processing a time-series of data from the past every time an prediction is updated. The iterative algorithms that form the basis for data assimilation (e.g., Kalman Filter) have on occasion been applied to disturbance detection (using statistical, rather than process-based model) and have demonstrated greater computational efficiency [@Ye2020]. @Ye2020 avoid the "no man's land" nudge problem by the simple expedient of performing threshold-based disturbance detection prior to assimilation and not assimilating disturbed sites. Third, other algorithms are relying on simple statistical models for their predictions of the status quo, such as harmonic time-series models, while the Multinomial model is relying on the predictions of a process-based ecosystem model. This has three distinct advantages: (1) We are leveraging greater process understanding in the status quo prediction, potentially making the algorithm more robust in the face of extreme events that are not disturbances (e.g., unusually cold or dry) but which alter the magnitude or phenology of seasonal cycles; (2) While not included in the simple "toy" model used in these analyses, process-based models also have the potential to leveraging greater process understanding in predicting the likelihood of disturbances, for example by accounting for fuel loads, fuel moisture, and ignition rates in predicting the likelihood of fire; (3) Because process-based models are predicting multiple pools and fluxes that can be compared to multiple distinct types of data, the Multinomial algorithm provides a natural way to fuse multiple types of data that would either reinforce a disturbance detection (if all sources are pointing in the same direction) or call it into question. While conventional disturbance detection algorithms are overwhelmingly based on multispectral remote sensing from either a single sensor or a pre-harmonized fusion of multiple sensors [e.g., Harmonized Landsat Sentinel-2, @CHEN2021; @SHANG2022], data assimilation approaches can simultanously integrate a wide range of relevant data types, for example lidar, microwave, thermal, solar-induced fluorescence, and field data. Data assimilation can also integrate a range of optical sensors (both multispectral and hyperspectral) based on their spectral response functions, rather than requiring pre-harmonization [@Shiklomanov2021; @Zhang2023]).
 

## Oregon case study

The most obvious issue with the initial application of the Multinomial filter to real-world data was the high incidence of filter divergence -- of the model becoming overconfident in itself and thus diverging from the observations. 
Filter divergence is not unique to this algorithm, but something that can occur in traditional filters as well. 
Indeed, there's no reason to belive that filter divergence is any more common in the Multinomial filter than in more traditional filters, such as EnKF, because in the absence of disturbance the Multinomial filter behaves exactly as EnKF would. 
The underlying causes of filter divergence are a result of either an underaccounting of model uncertainty or an overestimation of observation error in the data, both of which are likely at play in this example. 
On the model side, forecast uncertainty is associated with five factors: initial condition uncertainty, driver uncertainty, parameter uncertainty, parameter heterogenity, and process error [@Dietze2017b]. 
Since our goal here was a simple proof of concept, rather than a real world application, we did not formally account for uncertainty in model drivers (i.e., meteorology) or parameters. 
Alternative meteorological driver data products exist that account for uncertainties, such as the ERA5 ensemble reanalysis product [@Hersbach2020], and methods exist for propagating the uncertainties associated with downscaling such regional data products [@Rollinson2017].
Similarly, for actual carbon monitoring and forecasting we would recommend a more extensive multi-site Bayesian calibration so that parameter uncertainty can be propagated [@Fer2018; @Dietze2017a], preferably employing hierarchical approaches to also capture parameter heterogeneity (a.k.a. random effects), which can be substantial [@Fer2021].
Likewise, we would recommend a more robust estimation and propagation of process error as part of the data assimilation approach itself [@Raiho2020].
Ironically, the success of the existing model calibration at predicting AGB at our single calibration sites contributed to the underestimation of process error, since we failed to account for the uncertainties associated with extrapolating this single calibration to other sites across the landscape. 
Given the strong topographic and climatic gradients of the central Cascades, landscape heterogeneity in model performance is likely nontrivial.

In addition to underestimating model uncertainty, the AGB data product we are using, which relies on a single fixed residual error estimate, is likely overestimating the observation uncertainty. 
First, the assumption of constant variance is unlikely to be true because AGB is non-negative, which means the current interval estimates for low biomass sites include a substantial probability of negative biomass. 
More often the uncertainties in AGB are heteroskedastic and increasing in absolute magnitude as AGB increases, a property shared with the allometeric models used to estimate AGB in the field calibration data [@Dietze2008]. 
This heteroskedasticity particularly important for disturbance detection because it means we are likely significantly overestimating the observation error associated with low biomass (disturbed) conditions, contributing directly to the Multinomial model's inability to distinguish such biomass drops from observation error. 
Second, the AGB data product is does not distinguish random versus systematic errors [@Cameron2022], and in particular is not accounting for the spatial and temporal autocorrelation in observation errors. 
In reality, a site with higher than predicted AGB in one year is likely to have higher than predicted AGB the next year (positive temporal autocorrelation) and adjacent pixel are also likely to have higher than predicted AGB (positive spatial autocorrelation). 
These positive autocorrelations mean we are likely overestimating the uncertainty associated with change detection, since a substantial portion of this systematic observation error should cancel out [@Kennedy2023].
Overall, the failures of the default calibration, which ignored driver uncertainty, parameter uncertainty, and parameter heterogeneity while understimating process error and overestimating observation error, provide an illustrative case study in the care that must be taken when applying data assimilation approaches in general, and the Multinomial filter in particular, to real-world data

In contrast to our "off-the-shelf" application of the Multinomial filter, our computational experiments demonstrated that when we increase the model uncertainty and reduce the observation uncertainty that we significantly reduced the rate of filter divergence and were able to reliably detect all but the smallest disturbance events. 
Indeed, filter divergence declined, and disturbance detection increased, systematically as a function of the magnitude of the observation error. 
Somewhat surprisingly the computational experiments suggested that the Multinomial filter tended to be more sensitive to observation error than to model error, and suggesting that applications should prioritize making sure that observation errors are correctly accounted. 
Indeed, doing a better job at propagating model uncertainties correctly only becomes important once the observation errors are constrained.

## Future Directions: Current algorithm

In the following subsections we discuss ways that the proof-of-concept presented here could be applied and built upon. We start by addressing future directions that make use of the current algorithm "as is", discussing ways that we could better leverage multiple data constraints, improved disturbance priors, and existing disturbance data products.
In terms of multiple data constraints, it is worth noting that, unlike in the simulated data experiment, our real-world application only relied on a single data constraint.
If we had leveraged additional data constraints, we would have gained additional confidence in our ability to detect real disturbances.
One way to to do this is to bring in additional data on the same pool, in this case AGB, reducing the overall observation error. This could be done through some combination of field data [e.g., Forest Inventory and Analysis, CITE], lidar [e.g., GEDI, CITE], microwave vegetation optical depth [e.g., SMAP, CITE Koenings], or radar [e.g., BIOMASS, CITE]. 
This was not done in this example because data products based on different observations have a different spatial resolutions, which would need to be addressed. Fusing in a data assimilation framework is well established but was judged beyond the scope of the current study because it requires running a fully spatial assimilation rather than a simple site-scale timeseries model. Basically, one either needs to run the assimilation at a fine spatial resolution and use an observation operator to map many model grid cells to one observation, or one could run the assimilation at a coarse spatial resolution and use an observation operator to map one model grid cell to many observations [@Dietze2017a].

Another way would be to bring in additional data on different pools, such as LAI, which often has lower observation errors.
In addition to the direct increase in data volumes, the positive correlation between LAI and AGB would allow the assimilation algorithm to borrow strength indirectly (i.e. observations of LAI would help constrain AGB and observations of AGB would help constrain LAI). 
Existing LAI data products [e.g., MODIS, CITE] have the same spatial mismatch issue discussed above.
Alternatively, a data product based on LandSAT would be at the same resolution but would have required additional development [e.g., @Zhang2023] and would need to account for the observation error covariance between the two products (i.e. errors in data products based on the same underlying spectra would not be independent). 
In addition to bringing in additional data constratins on different pools, we could also constrain our disturbance estimates using observations on different ecosystem fluxes and processes, such as eddy covariance (carbon, water, and energy fluxes), solar induced fluorescence (a proxy for gross primary productivity), thermal imaging (a proxy for water stress and evapotranspiration).

In addition to constraining our estimates of disturbance through the ecosystem state variables, we can also improve them by improving our priors on the disturbance probability. 
In our simple case study we relied on static and spatially-homogenous prior probabilities on different disturbance rates, an approach somewhat similar to the simplest state-and-transition models of land use and disturbance [@Daniel2016].
More complex state-and-transition models are possible that allow these priors to be spatially heterogenous (e.g., relying on spatial covariates) or time evolving (e.g., relying on temporal covariates). Dynamic models are also possible that rely on the current state of a pixel (e.g., increasing fuel loads increase the probability of fire), the state of adjacent pixels (e.g., spatially contagious disturbances such as fire), or even those involving more distant spatial relations (e.g., dispersal kernels of biotic pests and pathogens) (CITATIONS).
In addition to relying on external state-and-transition models, one of the appeals of working with process-based ecosystem models is that many of they include submodules that represent different types of disturbance internally (e.g., fire, pests). In these cases we can either extract the model's internally predicted probabilities or simply rely on the frequency of events predicted across the ensemble of model runs.

The other way to improve upon the prior estimates of disturbance probability is to rely on external disturbance data that's not part of the assimilation itself. 
For example, in our Oregon case study it is clear that the Landtrendr disturbance product is "seeing" more about disturbance than is being expressed in the AGB product alone, as the the disturbance product is looking for different information (e.g., weighting bands differently, training to distinguish among types of disturbance not just a loss of biomass). 
Therefore, one alternative to relying on models to predict disturbance priors is to use the disturbance product and its classification error statistics to specify priors itself to identify the error.
This approach could be particularly valuable for distinguishing among alternative disturbance types (e.g., forest wildfire, forestry, and conversion to agriculture or development), especially for disturbance products that make use of bands outside of the normal optical range (e.g., thermal-based active fire products).
Applying this approach was not done in our test case because we wanted to keep the disturbance product separate for purposes of validation, but would be relatively straightforward to implement.
It's important to note that when using external disturbance data as priors we're still not prescribing disturbances deterministically, during the assimilation observations about ecosystem pools and fluxes would thus either reinforce these products or call them into question. 
Finally, it is worth nothing that relying on processed-based models and external disturbance data products are not mutually exclusive.
The fusion of disturbance products and disturbance models could be part of the future development of the Multinomial filter itself (see next subsection), but may be simpler to handle as part of the prior construction. For example, one could start with the models as priors and then update these using one or more disturbance product observations [e.g., using the Bayesian Updating of Land Cover (BULC) algorithm, @CARDILLE2016; @Crowley2019] and then use these posteriors as the priors in the data assimilation.

## Future Directions: Computational challenges

One of the challenges in scaling up the Multinomial filter is the computational cost involved. Unlike a traditional EnKF, the Analysis step of the data assimilation does not have a full analytically solution, and instead needs to be evaluated numerically, for example through standard Bayesian MCMC approaches as was done in this paper. 
However, MCMC is too computationally costly to apply using brute force on anything larger than an individual landscape. Here we discuss two possible approximations to the full algorithm, one analytical and the other based on model emulation. 
Analytically, instead of solving the full Multinomial filter jointly, it may be possible to approximate the full model by decompose the filter sequentially. 
First, one would analytically apply EnKF to each alternative disturbance state, analytically generating independent posteriors for each $X^L_t$.
Next, one would then apply a Dirlichet-Multinomial model to the problem of updating $\vec{\rho_t}$, treating $X^L_t$ as known rather than jointly estimated. The math for this approach has yet to be fully flushed out, and it remains to be seen how well this approximation works in practice and what information would be lost by solving the model conditionally rather than jointly.

An alternative to analytical approximation is to rely on machine learning approaches to build an emulator (a.k.a. surrogate model) [CITE]. While emulators are often used to approximate process-based models, predicting what the model would have output given a set of inputs, here we want to construct an emulator to that Analysis step, predicting what the Multinomial filter would output (probability of disturbance, ecosystem pool means and variances) as a function of the Forecast model state and the observed data constraints. ** Find citations for papers that have emulated other SDA**. Emulators addresses not only the computational cost of scaling up but also the observation that similar sites are going to make similar predictions (e.g., adjacent LANDSAT pixels), and thus fully gridded models are going to perform highly redundant calculations. Emulators still require running the model and analysis (in this case the Multinomial filter), but rather than evaluating every location the filter is run for a subset of locations stratified by relevant variables (initial conditions, observed data constraints, and posssibly also covariates like climate, soils, etc.). Flexible machine learning approaches are then used to build an emulator that predicts the outcome of full Bayesian model. For places where the full models was not run the emulator is then used to predict the full model, which in essence involves interpolating in environmental space and mapping this back to physical space.

## Future Directions: Algorithm Development

In this final section we discuss three future directions for improving upon the Multinomial filter: accounting for space when estimating the probability of disturbance, $\vec{\rho_t}$; adding memory to the algorithm to be able to better detect disturbance occurrence and type; and scaling up using spatially implicit approaches that track fractional area.

In terms of spatial disturbance probability, the current filter does estimate a whole vector of probabilities, one for each site, and thus estimates will include a posterior covariance structure across sites, but the mdoel is not written in a way that explicitly changes the probability of disturbance based on spatial adjacency. In practice, almost all types of disturbance involve some degree of shared risk, if not true spatial contagion, whereby a disturbance at one site usually increases the probability of disturbance in near-by sites. Accounting for this could be done by adding a hierarchical layer to the estimation of $\rho$ that includes a spatial covariance structure. Because $\rho$ is bound between zero and one, this could be done by including a link function (e.g., logit) and modeling the covariance as a multivariate Normal with a standard distance-dependent covariance model (e.g., exponential, Gaussian, Matern) [@Banerjee2014]. In practice, estimating larger spatial covariance matrices is computationally demanding and often more efficiently approximated using spatial basis functions and random effects [@Wikle2019].

As for the idea of incorporating memory into the Multinomial filter, one limitation of the existing approach is that (like most data assimilation filters) it is strictly Markovian - states are updated solely based on the current model state and current observations. Imagine the case where an anomalously low value is observed for AGB but at the next time point AGB returns to normal. At the time that the low observation is made it may trigger the Multinomial filter to predict a high probability of disturbance, but after the next observation becomes available it becomes much more likely that the low value was simply observation error. In this case what we want is the ability not just to restore the AGB to the undisturbed state, but also to jump back to the previous observation and assign it to be undisturbed as well. As another example, imagine the case where a disturbance does occur but the observations are compatible with multiple types of disturbance (e.g., clear cut versus conversion to agriculture). The algorithm may assign both a 50/50 probability at that time point, and then at the next time point it may update that assignment based on new information (e.g., the new year's vegetation is herbaceous). Rather than interpreting the 50% probability assigned to clear cut as a new transition at the second time point, what we'd really like to do is jump back in time and say, based on new information, that we're now much more confident that the original disturbance was agricultural conversion. Furthermore, because some PFT transitions are not easily reversible (e.g., a grassland cannot shift to a mature forest in one year), this capability to look back would also help protect against the risk that assigning a non-zero probability to a PFT transition could cause more and more of the ensemble to "leak" into that state. Implementing this "memory" feature is more challenging, as it requires writing a statistical model that accounts for multiple points in time and more complex multi-temporal disturbance state scenarios, as well as the informatics pipelines to save previous states and restart model ensembles from an earlier point in time. 

The final potential algorithm improvement would be to adopt a spatially implicit approach to tracking disturbance. Spatially implicit approaches are a common feature of global vegetation models, which might represent a larger (e.g. 1-by-1 degree) grid cell as containing multiple vegetation types, each with a fractional area, rather than keeping track of where in each grid cell those vegetation types are located. A subset of these models also keep track of both disturbance events and time since disturbance (a.k.a. patch age) in this way, updating fractional areas dynamically. Many of these models are derived from the size-and-age-structured (SAS) approximation introduced in the Ecosystem Demography (ED) model [@Moorcroft2001]. The idea is that if you consider a patch of vegetation of a specific age and vegetation type, a disturbance might only affect part of the patch, which would cause it to split into two patches (disturbed and undisturbed) each with a new fractional area. If this pattern were repeated over time the number of patches would increase exponentially over time, so ED also implements a patch fusion scheme that merges older patches back together when they are judged to have converged to equivalent states. More recently, @McCabe2019 proposed a way to account not just for fractional area but also patch adjacency using a spatially implicit approach, allowing for the model to better account for spatial contagion and the distribution of patch sizes. Conceptually, the disturbance data assimilation approach we've presented here should be able to be updated to keep track of fractional areas of disturbance instead of a discrete disturbed/undisturbed state, for example by adopting a Dirlichet data model instead of a Multinomial.

## Conclusion

Over the course of this paper we discussed the potential advantages of model-data assimilation for improving MRV of the terrestrial carbon cycle, the importance of disturbance to carbon MRV, and the limitations of current data assimilation algorithms to account for disturbance. We then derived a new data assimilation algorithm, the Multinomial filter, based on the idea of accounting for the discrete nature of disturbance, and demonstated the ability of this algorithm to capture a range of simulated and real-world disturbances. We then discussed ways that this algorithm could be further improved. Overall, the Multinomial filter has the potential to improve not only MRV but also the near real-time disturbance detection, with important implications at scales from national (UN reporting) down to local (natural climate solutions). By allowing a more realistic representation of disturbance in process-based models, the algorithm also opens the door to the incorporation of ecosystem recovery forecasts, making possible more informed and efficient management of post-disturbance recovery.








